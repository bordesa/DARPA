----------------------------------------------------------------- 
TEXT MODALITY PACKAGE 
Universite de Montreal - NetScale Team
----------------------------------------------------------------- 


1. Overview
----------------------------------------------------------------- 

This package proposes the complete pipeline from preprocessing,
unsupervised deep learning, supervised learning to kfold evaluation
for the text modality.

The architecture of the package is the following:

- src/     : contains python scripts to preprocess the data, train 
             the classifier and run the evaluation protocol.
- lib/     : contains protobuf and Liblinear library sources.
- DLmodel/ : contains the source code of the DL system. In Save_Model/ is
             located the hyperparameters configuration file required
             by the DL system and are saved the DL models and 
	     representations after training.
- script/  : contains shell scripts to install the libraries, preprocess
             the data and run the evaluation protocol.

This README details how to install this package and run the evaluation
protocol. To do so, you will need first to install google protocol
buffers and Liblinear locally.  Scripts are provided to configure and
compile both of these libraries, and instructions on how to compile
them are in this document.


2. 3rd Party Libraries
-----------------------------------------------------------------

Two installation scripts are provided, and they should be run in order:

Install libraries:

sh ./script/install-prototype-buffers-locally.sh
sh ./script/install-liblinear-locally.sh

Perform an additional code-generation step:

sh ./script/gen-protobuf-code.sh

the DL source code requires other libraries. Please refer to
/DLmodel/README for more details.


3.  Generating preprocessed data files
-----------------------------------------------------------------

If the above steps occurred without error, you should be able to
generate the preprocessed data with line on the shell (beforehand you
need to specify the path to your OpenTable db files in the script):

sh ./script/preprocess-and-split-data.sh

This script generates 5 files (in the package root):
- featDict.txt: the features dictionary. The word on the n-th line 
  corresponds to the feature n. The 2nd column gives the word count 
  of the word in the whole database.
- preprocessed-opentable-{train/test}.{vec/lab}: the train and test
  data files in the following format:
     *.vec files are the preprocessed reviews written in a LibSVM
      fashion without the labels. Each line corresponds to a review
      where each non-zero feature is indicated with
      <feature_index>:<feature_value>.
     *.lab files contain the labels. Each line corresponds to a review
      of the .vec file. Each column displays labels for a given task
      in the following order: Overall Food Ambiance Service Noise.

Note: the train/test split is created using a list of restaurant IDs
(in script/TrainRestaurantsIds-example.dat). The given example meets
the 70%/30% BEP-v3 recommendation. Define an other split can be easily
done by modifying script/TrainRestaurantsIds-example.dat.


4.  Training (and testing) a single classifier
-----------------------------------------------------------------

The linear classifier, which is learnt with Liblinear package, is a
standard a logistic regression outputting the expected rating (to
output a continuous rating). The metric used is the RMSE.

To train a classifier, simply run:
sh ./script/train-and-test-svm.sh TASK TRAIN_VEC TRAIN_LAB TRAIN_IDX TEST_VEC TEST_LAB
- TASK is the ID of the task from 0 to 4 (in the following order: Overall 
  Food Ambiance Service Noise)
- TRAIN_IDX is the list of index of the training set (i.e. TRAIN_VEC +
  TRAIN_LAB)corresponding to the training examples for the classifier
  (the others are used for validation). An example of TRAIN_IDX file
  is given: /script/ClassifierTrainIdxs-example.dat.

The script performs a line search with 10 steps to find the C value
reaching the lowest validation error, and computes the test RMSE
score with the corresponding model.

For example, to train a classifier for the 'overall rating' task on the
preprocessed files generated in 2., do:
sh ./script/train-and-test-svm.sh 0 preprocessed-opentable-train.vec preprocessed-opentable-train.lab /script/ClassifierTrainIdxs-example.dat preprocessed-opentable-test.vec preprocessed-opentable-test.lab


5.  Running evaluation protocol
-----------------------------------------------------------------

Running he whole evaluation protocol only requires the preprocessed
data (see 3.). Then you can simply do:

sh ./script/kfold-evaluation.sh

The script first trains the DL system, using the hyperparameters
defined in /DLmodel/Saved_Model/DARPA.conf, and creates the
representations corresponding to the 1-layer and 3-layers system (they
are stored in DLmodel/Save_Model/).  Then, for each task, it runs the
10-folds cross- validation procedure over a set of 1,0000 examples
(the classifier being trained on 1,000 examples each time and
validated on the remaining ones from the training set, i.e. ~300k
examples.  The 10,000 set selection and the folds creation meet BEP-v3
specifications (Stratified sampling).  In the end, the averaged RMSE
score over the 10 folds for each task, and each system
(baseline,shallow,deep) is printed.
